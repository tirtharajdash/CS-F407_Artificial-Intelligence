{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e964b21",
   "metadata": {},
   "source": [
    "### LLM + RAG demonstration: Neurosymbolic AI and their application in Science\n",
    "\n",
    "February 2026\n",
    "\n",
    "This notebook demonstrates Retrieval-Augmented Generation (RAG) over a corpus of neurosymbolic AI and drug discovery papers, co-authored by [Tirtharaj Dash](https://tirtharajdash.github.io). This notebook may contain bugs, if so please let TD know. Also, this notebook is a part of the AI course (CS F407) only designed for demonstration.\n",
    "\n",
    "**We have used the following models:**\n",
    "- Encoder: `BAAI/bge-small-en-v1.5` (dense retrieval, 384-dim)\n",
    "- Generator: `Qwen/Qwen2.5-3B-Instruct` (instruction-tuned, ~6 GB RAM)\n",
    "\n",
    "To use a lighter model (CPU-only): set `GEN_MODEL = \"HuggingFaceTB/SmolLM2-1.7B-Instruct\"`  \n",
    "To use a heavier model (better quality): set `GEN_MODEL = \"mistralai/Mistral-7B-Instruct-v0.3\"`\n",
    "\n",
    "**Libraries and packages to be installed before running this notebook**:\n",
    "```python\n",
    "#BE CAREFUL!!! IT MIGHT MESS YOUR ENV. I SUGGEST CREATE A NEW ENV and RUN THIS NOTEBOOK.\\\n",
    "#!pip install -q pymupdf sentence-transformers faiss-cpu transformers accelerate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eddba6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers directory : /home/tirtharaj/dash/CS-F407_Artificial-Intelligence/labs/Lab3/Dash_NeuroSym_Paps\n",
      "PDFs found       : 0\n",
      "Embed model      : BAAI/bge-small-en-v1.5\n",
      "Generator model  : Qwen/Qwen2.5-3B-Instruct\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "PAPERS_DIR   = Path(\"Dash_NeuroSym_Paps\")   # folder with our papers' PDFs\n",
    "INDEX_FILE   = Path(\"neurosym.index\")       # FAISS index (saved after first build)\n",
    "CORPUS_FILE  = Path(\"neurosym_corpus.pkl\")  # chunk text + metadata\n",
    "\n",
    "CHUNK_WORDS  = 200    # words per chunk\n",
    "OVERLAP      = 40     # word overlap between consecutive chunks\n",
    "\n",
    "EMBED_MODEL  = \"BAAI/bge-small-en-v1.5\"  # 384-dim, fast, good quality\n",
    "TOP_K        = 4                         # chunks to retrieve per query\n",
    "\n",
    "GEN_MODEL    = \"Qwen/Qwen2.5-3B-Instruct\"   # good enough model\n",
    "MAX_NEW_TOK  = 350\n",
    "\n",
    "print(f\"Papers directory : {PAPERS_DIR.resolve()}\")\n",
    "print(f\"PDFs found       : {len(list(PAPERS_DIR.glob('*.pdf')))}\")\n",
    "print(f\"Embed model      : {EMBED_MODEL}\")\n",
    "print(f\"Generator model  : {GEN_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f33a76",
   "metadata": {},
   "source": [
    "**We need to first ingest PDFs and build FAISS index.**\n",
    "\n",
    "Each PDF is split into overlapping word-level chunks. Each chunk is embedded by\n",
    "`BAAI/bge-small-en-v1.5` and stored in a FAISS inner-product index (equivalent\n",
    "to cosine similarity after L2 normalisation).\n",
    "\n",
    "The index is saved to disk so this step runs only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc70005f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing index ...\n",
      "Index loaded: 1094 vectors, dim=384\n"
     ]
    }
   ],
   "source": [
    "import pymupdf as fitz                                  # PyMuPDF\n",
    "import pickle\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def extract_chunks(pdf_path: Path, chunk_words: int, overlap: int):\n",
    "    \"\"\"Extract overlapping word-level chunks from a PDF.\"\"\"\n",
    "    doc  = fitz.open(str(pdf_path))\n",
    "    text = \" \".join(page.get_text() for page in doc)\n",
    "    doc.close()\n",
    "\n",
    "    words  = text.split()\n",
    "    stride = chunk_words - overlap\n",
    "    chunks, meta = [], []\n",
    "    for i in range(0, len(words), stride):\n",
    "        chunk = \" \".join(words[i : i + chunk_words])\n",
    "        if len(chunk.strip()) < 60:          # skip near-empty trailing chunks\n",
    "            continue\n",
    "        chunks.append(chunk)\n",
    "        meta.append({\"source\": pdf_path.name, \"word_offset\": i})\n",
    "    return chunks, meta\n",
    "\n",
    "\n",
    "def build_index(papers_dir: Path, chunk_words: int, overlap: int,\n",
    "                embed_model_name: str, index_file: Path, corpus_file: Path):\n",
    "    pdfs = sorted(papers_dir.glob(\"*.pdf\"))\n",
    "    assert pdfs, f\"No PDFs found in {papers_dir}\"\n",
    "\n",
    "    print(f\"Ingesting {len(pdfs)} PDFs ...\")\n",
    "    corpus, metadata = [], []\n",
    "    for pdf in tqdm(pdfs, desc=\"Parsing PDFs\"):\n",
    "        c, m = extract_chunks(pdf, chunk_words, overlap)\n",
    "        corpus.extend(c)\n",
    "        metadata.extend(m)\n",
    "    print(f\"Total chunks: {len(corpus)}\")\n",
    "\n",
    "    print(f\"\\nEncoding with {embed_model_name} ...\")\n",
    "    encoder    = SentenceTransformer(embed_model_name)\n",
    "    embeddings = encoder.encode(\n",
    "        corpus, batch_size=64, show_progress_bar=True,\n",
    "        convert_to_numpy=True, normalize_embeddings=True  # L2-normalise -> cosine via IP\n",
    "    )\n",
    "\n",
    "    dim   = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatIP(dim)   # inner product on unit vectors = cosine similarity\n",
    "    index.add(embeddings)\n",
    "\n",
    "    faiss.write_index(index, str(index_file))\n",
    "    with open(corpus_file, \"wb\") as f:\n",
    "        pickle.dump((corpus, metadata), f)\n",
    "\n",
    "    print(f\"\\nIndex saved to  : {index_file}\")\n",
    "    print(f\"Corpus saved to : {corpus_file}\")\n",
    "    return index, corpus, metadata, encoder\n",
    "\n",
    "\n",
    "# Build or load\n",
    "if INDEX_FILE.exists() and CORPUS_FILE.exists():\n",
    "    print(\"Loading existing index ...\")\n",
    "    index = faiss.read_index(str(INDEX_FILE))\n",
    "    with open(CORPUS_FILE, \"rb\") as f:\n",
    "        corpus, metadata = pickle.load(f)\n",
    "    encoder = SentenceTransformer(EMBED_MODEL)\n",
    "    print(f\"Index loaded: {index.ntotal} vectors, dim={index.d}\")\n",
    "else:\n",
    "    index, corpus, metadata, encoder = build_index(\n",
    "        PAPERS_DIR, CHUNK_WORDS, OVERLAP, EMBED_MODEL, INDEX_FILE, CORPUS_FILE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e6fbd3",
   "metadata": {},
   "source": [
    "**Retrieval function**\n",
    "\n",
    "Given a query string $q$, compute $\\mathbf{e}_q = f_\\phi(q)$ and return the\n",
    "top-$k$ chunks by cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44827629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 4 chunks for sanity check:\n",
      "  [0.809] 2510.23379v1.pdf\n",
      "  [0.790] 27751-Article Text-31805-1-2-20240324.pdf\n",
      "  [0.787] 2510.23379v1.pdf\n",
      "  [0.784] 2510.23379v1.pdf\n"
     ]
    }
   ],
   "source": [
    "def retrieve(query: str, k: int = TOP_K):\n",
    "    \"\"\"\n",
    "    Embed query and return top-k chunks with scores and source filenames.\n",
    "    Returns a list of dicts: {chunk, source, score}\n",
    "    \"\"\"\n",
    "    q_emb = encoder.encode(\n",
    "        [query], convert_to_numpy=True, normalize_embeddings=True\n",
    "    )\n",
    "    scores, indices = index.search(q_emb, k)\n",
    "    results = []\n",
    "    for score, idx in zip(scores[0], indices[0]):\n",
    "        results.append({\n",
    "            \"chunk\":  corpus[idx],\n",
    "            \"source\": metadata[idx][\"source\"],\n",
    "            \"score\":  float(score)\n",
    "        })\n",
    "    return results\n",
    "\n",
    "\n",
    "def show_retrieved(hits):\n",
    "    for i, h in enumerate(hits):\n",
    "        print(f\"\\n--- Chunk {i+1} | source: {h['source']} | score: {h['score']:.3f} ---\")\n",
    "        print(h[\"chunk\"][:400], \"...\" if len(h[\"chunk\"]) > 400 else \"\")\n",
    "\n",
    "\n",
    "# doing here a sanity check\n",
    "test_hits = retrieve(\"neurosymbolic drug discovery\")\n",
    "print(f\"Retrieved {len(test_hits)} chunks for sanity check:\")\n",
    "for h in test_hits:\n",
    "    print(f\"  [{h['score']:.3f}] {h['source']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b719aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886160ef2e8e4d0f962cba097e2c749b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator loaded: Qwen/Qwen2.5-3B-Instruct\n"
     ]
    }
   ],
   "source": [
    "# Generator LLM\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(GEN_MODEL)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    GEN_MODEL,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=MAX_NEW_TOK,\n",
    "    do_sample=False,      # greedy for reproducibility in class demo\n",
    "    temperature=None,\n",
    "    top_p=None\n",
    ")\n",
    "print(f\"Generator loaded: {GEN_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7c3b2d",
   "metadata": {},
   "source": [
    "**RAG inference**\n",
    "\n",
    "Two functions:\n",
    "- `llm_only(query)`: parametric generation, no retrieval\n",
    "- `rag_answer(query)`: retrieve then generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f530ef84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions defined: llm_only(), rag_answer()\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PLAIN = (\n",
    "    \"You are a knowledgeable AI research assistant. \"\n",
    "    \"Answer the question as accurately as you can.\"\n",
    ")\n",
    "\n",
    "SYSTEM_RAG = (\n",
    "    \"You are a precise research assistant. \"\n",
    "    \"Answer the question using ONLY the provided context. \"\n",
    "    \"If the answer is not in the context, say: 'Not found in the provided documents.' \"\n",
    "    \"Always state which paper (source) supports your answer.\"\n",
    ")\n",
    "\n",
    "\n",
    "def build_prompt(system: str, context: str, query: str) -> str:\n",
    "    \"\"\"Build a chat-style prompt compatible with Qwen2.5 / Mistral / SmolLM2.\"\"\"\n",
    "    messages = [{\"role\": \"system\", \"content\": system}]\n",
    "    user_content = f\"{query}\" if not context else (\n",
    "        f\"Context from research papers:\\n\\n{context}\\n\\nQuestion: {query}\"\n",
    "    )\n",
    "    messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "    return tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_answer(raw_output: str, prompt: str) -> str:\n",
    "    \"\"\"Strip the prompt prefix from generator output.\"\"\"\n",
    "    return raw_output[len(prompt):].strip()\n",
    "\n",
    "\n",
    "def llm_only(query: str) -> str:\n",
    "    \"\"\"Pure parametric generation — no retrieval.\"\"\"\n",
    "    prompt = build_prompt(SYSTEM_PLAIN, \"\", query)\n",
    "    raw    = generator(prompt)[0][\"generated_text\"]\n",
    "    return extract_answer(raw, prompt)\n",
    "\n",
    "\n",
    "def rag_answer(query: str, k: int = TOP_K):\n",
    "    \"\"\"Retrieve top-k chunks, then generate a grounded answer.\"\"\"\n",
    "    hits    = retrieve(query, k)\n",
    "    context = \"\\n\\n\".join(\n",
    "        f\"[Source: {h['source']} | relevance: {h['score']:.3f}]\\n{h['chunk']}\"\n",
    "        for h in hits\n",
    "    )\n",
    "    prompt = build_prompt(SYSTEM_RAG, context, query)\n",
    "    raw    = generator(prompt)[0][\"generated_text\"]\n",
    "    return extract_answer(raw, prompt), hits\n",
    "\n",
    "\n",
    "print(\"Functions defined: llm_only(), rag_answer()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d52387a",
   "metadata": {},
   "source": [
    "**Test: LLM-only vs RAG-augmented**\n",
    "\n",
    "For each query we show:\n",
    "1. The LLM-only answer (parametric; may hallucinate)\n",
    "2. The retrieved chunks (with source filenames and similarity scores)\n",
    "3. The RAG-augmented answer (grounded; attributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dd465b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "QUERY: What symbolic representation is used for molecules in Dash et al.'s neurosymbolic framework?\n",
      "================================================================================\n",
      "\n",
      "[LLM-only answer]\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize, but there seems to be an error in your question as no specific paper titled \"Dash et al.\" with a neurosymbolic framework specifically about molecular representations has been widely recognized in the literature up to my last update in October 2023.\n",
      "\n",
      "However, if you're referring to a neurosymbolic framework that deals with molecular representations, one common approach is to use chemical formulas or molecular structures as symbols. In computational models, these might be represented using SMILES (Simplified Molecular Input Line Entry System) or InChI (International Chemical Identifier) strings, which are standardized ways of encoding molecular structures.\n",
      "\n",
      "If you have more context or details about the specific framework you're referring to, I'd be happy to provide a more accurate answer based on that information.\n",
      "\n",
      "[Retrieved chunks]\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 | source: 2510.23379v1.pdf | score: 0.834 ---\n",
      "represented as a Grothendieck construction over an indexed family of partially-ordered sets. The construction yields a unified space linking symbolic and neural generation. • We implement and test SNGs on the real-world problem of generating potential in- hibitors for protein-targets. This constitutes the problem of ‘lead-discovery’, and re- alistic settings have the following charactestics. Given ...\n",
      "\n",
      "--- Chunk 2 | source: 2510.23379v1.pdf | score: 0.832 ---\n",
      "the implementation – instances generated – is also true of the specification (satisfies the constraints of the symbolic model). Unlike with classic formal methods, in SNG ML techniques play a role in obtaining both the specification and the implementation. We have proposed using the mathematical structure of fibered-posets by way of specifying the codomain of an SNG system. The paired elements com ...\n",
      "\n",
      "--- Chunk 3 | source: 2510.23379v1.pdf | score: 0.825 ---\n",
      "distribution. The set X is the set of instances generated that are in S. We see the paper contributing in the following ways to research into neurosymbolic systems: • We identify a class of hybrid neurosymbolic systems – called Symbolic Neural Gener- ators, or SNGs – which draws on the strengths of symbolic learning and neural-based generative models. Potential symbolic descriptions are examined,  ...\n",
      "\n",
      "--- Chunk 4 | source: 2510.23379v1.pdf | score: 0.809 ---\n",
      "rests on the observation that “the activity of any neu- ron can be represented as a proposition”. Thus arises an entire class of systems comprising a purely connectionist approach that approximate the patterns of categoric inference arising when using (often propositional, but not always) logical representations, as well as the pat- terns of plausible inference that arise when using probabilistic  ...\n",
      "\n",
      "[RAG answer]\n",
      "----------------------------------------\n",
      "Not found in the provided documents.\n",
      "\n",
      "================================================================================\n",
      "QUERY: How is background knowledge encoded in the ILP-based drug discovery approach?\n",
      "================================================================================\n",
      "\n",
      "[LLM-only answer]\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In an Inductive Logic Programming (ILP)-based drug discovery approach, background knowledge is typically encoded through logical rules or constraints that guide the learning process. Here's how it is usually implemented:\n",
      "\n",
      "1. **Rule Encoding**: Background knowledge is first formalized into logical rules or constraints. These rules often represent biological knowledge, chemical properties, and disease mechanisms relevant to the drug discovery problem. For example, a rule might state that \"a compound X interacts with protein Y if it has a certain binding affinity.\"\n",
      "\n",
      "2. **Knowledge Base Construction**: The encoded rules are compiled into a knowledge base. This knowledge base serves as the training data for the ILP system, providing context and prior information about what constitutes a valid solution.\n",
      "\n",
      "3. **Learning Algorithm**: An ILP algorithm then processes this knowledge base to learn patterns and relationships that generalize from the provided examples to new instances. The algorithm searches for hypotheses that best fit both the given examples and the background knowledge.\n",
      "\n",
      "4. **Constraint Satisfaction**: During the learning process, the ILP system must satisfy not only the positive examples but also the constraints imposed by the background knowledge. This ensures that the learned hypotheses are consistent with existing biological and chemical understanding.\n",
      "\n",
      "5. **Hypothesis Generation**: The system generates candidate hypotheses based on the available background knowledge. These hypotheses are evaluated against the training data to ensure they are both accurate and consistent with the provided knowledge.\n",
      "\n",
      "6. **Refinement and Iteration**: The learned hypotheses are refined through iterative refinement processes, where the system may modify or add to the hypotheses to better align with the background knowledge and the data.\n",
      "\n",
      "By encoding background knowledge in this manner, the ILP-based drug discovery approach aims to leverage existing scientific knowledge to guide the search for novel drug candidates, potentially\n",
      "\n",
      "[Retrieved chunks]\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 | source: PhD_Thesis_Final.pdf | score: 0.812 ---\n",
      "novel molecules for early-stage drug design. We show how a graph-based neural network with domain-knowledge is one component in a modular system design. Specifically, our conclusions from this chapter are as follows: (1) We have constructed a complete end- to-end neural-symbolic system that is capable of generating active molecules that may not be in any existing database; (2) We have demonstrated ...\n",
      "\n",
      "--- Chunk 2 | source: 2021.07.09.451519v2.full.pdf | score: 0.810 ---\n",
      "Using Domain-Knowledge to Assist Lead Discovery in Early-Stage Drug Design Tirtharaj Dash1, Ashwin Srinivasan1, Lovekesh Vig2, and Arijit Roy3 1 Dept. of CSIS & APPCAIR, BITS Pilani, Goa Campus, India 2 TCS Research, New Delhi, India 3 TCS Innovation Labs (Life Sciences Division), Hyderabad, India Abstract. We are interested in generating new small molecules which could act as inhibitors of a biol ...\n",
      "\n",
      "--- Chunk 3 | source: 27751-Article Text-31805-1-2-20240324.pdf | score: 0.800 ---\n",
      "early-stage drug design (see Fig. 1(a) showing the use of a Robot Scientist) as virtual screening, identifying qualita- tive and quantitative structure-activity relations (SARs) and so on. The broader picture is of a semi-automated scientific discovery pipeline involving feedback from from computa- tional chemists, synthetic chemists, and biologists and man- ufacturers, using results from simulati ...\n",
      "\n",
      "--- Chunk 4 | source: PhD_Thesis_Final.pdf | score: 0.797 ---\n",
      "2018. [SKTW17] Marwin H.S. Segler, Thierry Kogej, Christian Tyrchan, and Mark P. Waller. Generating focused molecule libraries for drug discovery with re- current neural networks. ACS Central Science, 4(1):120–131, 2017. [SLM20] Mattia Silvestri, Michele Lombardi, and Michela Milano. Injecting domain knowledge in neural networks: a controlled experiment on a constrained problem. arXiv preprint arX ...\n",
      "\n",
      "[RAG answer]\n",
      "----------------------------------------\n",
      "According to the provided context from \"PhD_Thesis_Final.pdf\" (relevance: 0.812), background knowledge is encoded in the ILP-based drug discovery approach by utilizing Inductive Logic Programming (ILP) techniques. Specifically, it mentions that the problem involves drawing instances from the conditional distribution of molecules given both domain-specific knowledge (B) and activity data (Y), DX|Y,B. The design consists of generators to approximate these distributions, incorporating symbolic domain-knowledge to assist in exploring the vast space of possible molecules.\n",
      "\n",
      "================================================================================\n",
      "QUERY: What deep learning models Dash has worked on?\n",
      "================================================================================\n",
      "\n",
      "[LLM-only answer]\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but there seems to be some confusion. There is no widely known entity called \"Dash\" that has been involved in deep learning model development. It's possible you might be thinking of Dash (company), which is a financial technology company, or Dash (software), which is a decentralized cryptocurrency. However, neither of these entities is typically associated with deep learning model development.\n",
      "\n",
      "If you meant to ask about a specific individual named Dash who works on deep learning models, I would need more context to provide accurate information. If you could clarify the name or provide additional details, I'd be happy to assist further.\n",
      "\n",
      "[Retrieved chunks]\n",
      "----------------------------------------\n",
      "\n",
      "--- Chunk 1 | source: PhD_Thesis_Final.pdf | score: 0.742 ---\n",
      "machines”, International Con- ference on Artificial Neural Networks, 2019. URL: https://doi.org/10.1007/978-3-030-30484-3_3 6. T. Dash, A. Srinivasan, L. Vig, O.I. Orhobor, R.D. King, “Large-scale assessment of deep relational machines”, International Conference on Inductive Logic Program- ming, 2018. URL: https://doi.org/10.1007/978-3-319-99960-9_2 (⋆Winner of the Best Student Paper Award) 187 Th ...\n",
      "\n",
      "--- Chunk 2 | source: s41598-021-04590-0.pdf | score: 0.717 ---\n",
      "networks on a wide variety of tasks makes a substantial case for their use in model construction, it is not immediately obvious how either (1) or (2) should be done with deep neural networks. In this paper, we examine ways of achieving (1), that is, the techniques for constructing deep neural networks from data and domain-knowledge concerning the problem. Understanding models constructed by deep n ...\n",
      "\n",
      "--- Chunk 3 | source: s10994-023-06399-6.pdf | score: 0.715 ---\n",
      "(1989). Approximation by superpositions of a sigmoidal function. Mathematics of Control, Signals and Systems, 2(4), 303–314. https://​doi.​org/​10.​1007/​BF025​51274 Dash, T., Srinivasan, A., Vig, L., Orhobor, O. I., & King, R. D. (2018). Large-scale assessment of deep relational machines. In International conference on inductive logic programming (pp 22–37). Springer. Dash, T., Srinivasan, A., Jo ...\n",
      "\n",
      "--- Chunk 4 | source: s10994-021-06090-8.pdf | score: 0.715 ---\n",
      "as the first of 3 Grand Challenges for ML and AI: “ML and AI are generally domain-agnostic ...Off-the-shelf practice treats [each of these] datasets in the same way and ignores domain knowledge that extends far beyond the raw data itself—such as physical laws, available forward simulations, and established invariances and symmetries—that is readily available ...Improving our ability to systematica ...\n",
      "\n",
      "[RAG answer]\n",
      "----------------------------------------\n",
      "Based on the information provided in the context, Thomas Dash has worked on the following deep learning models:\n",
      "\n",
      "1. Deep Relational Machines\n",
      "2. Graph Neural Networks (GNNs)\n",
      "3. Mode-Directed Inverse Entailment for GNNs\n",
      "\n",
      "These models are referenced through various publications listed in the context.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DEMO_QUERIES = [\n",
    "    \"What symbolic representation is used for molecules in Dash et al.'s neurosymbolic framework?\",\n",
    "    \"How is background knowledge encoded in the ILP-based drug discovery approach?\",\n",
    "    \"What deep learning models Dash has worked on?\"\n",
    "]\n",
    "\n",
    "SEP = \"=\" * 80\n",
    "\n",
    "for query in DEMO_QUERIES:\n",
    "    print(SEP)\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(SEP)\n",
    "\n",
    "    print(\"\\n[LLM-only answer]\")\n",
    "    print(\"-\" * 40)\n",
    "    ans_plain = llm_only(query)\n",
    "    print(ans_plain)\n",
    "\n",
    "    print(\"\\n[Retrieved chunks]\")\n",
    "    print(\"-\" * 40)\n",
    "    ans_rag, hits = rag_answer(query)\n",
    "    show_retrieved(hits)\n",
    "\n",
    "    print(\"\\n[RAG answer]\")\n",
    "    print(\"-\" * 40)\n",
    "    print(ans_rag)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38e57434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question:  Who are the co-authors of Dash in his papers?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "[LLM-only]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but there isn't enough information provided in your question to determine who the co-authors of Dash are in specific papers. The name \"Dash\" is quite generic and could refer to many different individuals across various fields of study. Could you please provide more context or specify which field or particular paper you're referring to?\n",
      "\n",
      "[Retrieved chunks]\n",
      "\n",
      "--- Chunk 1 | source: PhD_Thesis_Final.pdf | score: 0.636 ---\n",
      "machines”, International Con- ference on Artificial Neural Networks, 2019. URL: https://doi.org/10.1007/978-3-030-30484-3_3 6. T. Dash, A. Srinivasan, L. Vig, O.I. Orhobor, R.D. King, “Large-scale assessment of deep relational machines”, International Conference on Inductive Logic Program- ming, 2018. URL: https://doi.org/10.1007/978-3-319-99960-9_2 (⋆Winner of the Best Student Paper Award) 187 Th ...\n",
      "\n",
      "--- Chunk 2 | source: PhD_Thesis_Final.pdf | score: 0.589 ---\n",
      "MONDAL Designation : Associate Professor Department of Biological Sciences BITS Pilani, K.K. Birla Goa Campus Place : Goa Date : BIRLA INSTITUTE OF TECHNOLOGY AND SCIENCE PILANI – 330 031 (INDIA) DECLARATION I, Tirtharaj Dash, declare that this thesis entitled “Inclusion of Symbolic Domain- Knowledge into Deep Neural Networks”, submitted by me under the supervision of Ashwin Srinivasan and co-supe ...\n",
      "\n",
      "--- Chunk 3 | source: PhD_Thesis_Final.pdf | score: 0.585 ---\n",
      "MICCAI Workshop on Thoracic Image Analysis, 2020. URL: https://doi.org/10.1007/978-3-030-62469-9_6 188 8. S. Yalburgi, T. Dash, R. Hebbalaguppe, S. Hegde, A. Srinivasan, “An Empirical Study of Iterative Knowledge Distillation for Neural Network Compression”, Eu- ropean Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, 2020. URL: https://www.esann.org/.../pro ...\n",
      "\n",
      "--- Chunk 4 | source: s10994-023-06399-6.pdf | score: 0.580 ---\n",
      "(1989). Approximation by superpositions of a sigmoidal function. Mathematics of Control, Signals and Systems, 2(4), 303–314. https://​doi.​org/​10.​1007/​BF025​51274 Dash, T., Srinivasan, A., Vig, L., Orhobor, O. I., & King, R. D. (2018). Large-scale assessment of deep relational machines. In International conference on inductive logic programming (pp 22–37). Springer. Dash, T., Srinivasan, A., Jo ...\n",
      "\n",
      "[RAG answer]\n",
      "Based on the information provided in the context, Tirtharaj Dash's co-authors include:\n",
      "\n",
      "1. Ashwin Srinivasan\n",
      "2. L. Vig\n",
      "3. O.I. Orhobor\n",
      "4. R.D. King\n",
      "5. Ashwin Srinivasan, R.S. Joshi, A. Baskar\n",
      "6. Ashwin Srinivasan, L. Vig\n",
      "7. Ashwin Srinivasan, A. Baskar\n",
      "8. Ashwin Srinivasan, L. Vig, A. Srinivasan, T. Dash\n",
      "9. Ashwin Srinivasan, A. Sonwane, G. Shroff, L. Vig, A. Srinivasan, T. Dash\n",
      "10. Ashwin Srinivasan, I. Olier, O.I. Orhobor, T. Dash, A.M. Davis, L.N. Soldatova, J. Vanschoren, R.D. King\n",
      "11. Ashwin Srinivasan, S. Chitlangia, A. Sonwane, T. Dash\n",
      "\n",
      "The context does not provide co-authorship details for all papers mentioned, but it clearly indicates that Ashwin Srinivasan is a frequent collaborator of Tirtharaj Dash.\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter your question: \").strip()\n",
    "if query:\n",
    "    print(SEP)\n",
    "    print(\"[LLM-only]\")\n",
    "    print(llm_only(query))\n",
    "\n",
    "    print(\"\\n[Retrieved chunks]\")\n",
    "    ans, hits = rag_answer(query)\n",
    "    show_retrieved(hits)\n",
    "\n",
    "    print(\"\\n[RAG answer]\")\n",
    "    print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "829059c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total papers  : 9\n",
      "Total chunks  : 1094\n",
      "Avg chunks    : 121.6\n",
      "\n",
      "                                    paper  chunks\n",
      "                     PhD_Thesis_Final.pdf     456\n",
      "                   s10994-021-06090-8.pdf     135\n",
      "                   s10994-023-06399-6.pdf     117\n",
      "                         2510.23379v1.pdf     103\n",
      "                   s41598-021-04590-0.pdf      73\n",
      "                   s10994-021-05966-z.pdf      70\n",
      "             2021.07.09.451519v2.full.pdf      50\n",
      "                  978-3-030-30484-3_3.pdf      47\n",
      "27751-Article Text-31805-1-2-20240324.pdf      43\n"
     ]
    }
   ],
   "source": [
    "# a sanity checker\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "source_counts = Counter(m[\"source\"] for m in metadata)\n",
    "df = pd.DataFrame(source_counts.items(), columns=[\"paper\", \"chunks\"])\n",
    "df = df.sort_values(\"chunks\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(f\"Total papers  : {len(df)}\")\n",
    "print(f\"Total chunks  : {df['chunks'].sum()}\")\n",
    "print(f\"Avg chunks    : {df['chunks'].mean():.1f}\")\n",
    "print()\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106484b1-6e26-45dd-b443-ee02889a6d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
